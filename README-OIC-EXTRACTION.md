# ðŸŽ« TICKET 4-bis â€” Extraction API-first des 4,872 objectifs EDN

Script d'extraction optimisÃ© des compÃ©tences OIC depuis l'API MediaWiki de LiSA UNESS.

## ðŸš€ Setup

### 1. Variables d'environnement

CrÃ©er un fichier `.env` :

```bash
# Authentification CAS UNESS
CAS_USER=laeticia.moto-ngane@etud.u-picardie.fr
CAS_PASS=Aiciteal1!

# Supabase
SUPABASE_URL=https://yaincoxihiqdksxgrsrk.supabase.co
SUPABASE_SERVICE_ROLE_KEY=<votre_clÃ©_service_role>
```

### 2. Installation des dÃ©pendances

```bash
npm install @supabase/supabase-js puppeteer dotenv
# ou
deno cache --reload src/scripts/scrape_oic.ts
```

## ðŸŽ¯ Utilisation

### Extraction complÃ¨te

```bash
# Node.js
node src/scripts/scrape_oic.ts

# Deno  
deno run --allow-net --allow-env --allow-write src/scripts/scrape_oic.ts
```

### Via l'interface web

1. Aller sur `/admin/extract-objectifs`
2. Cliquer sur "DÃ©marrer l'extraction"
3. Suivre le progrÃ¨s en temps rÃ©el

## ðŸ”§ Architecture technique

### Flux d'extraction

1. **Test API publique** : VÃ©rification si `api.php` est accessible sans authentification
2. **Authentification CAS** : Si nÃ©cessaire, login via Puppeteer minimal pour rÃ©cupÃ©rer les cookies
3. **Listing des pages** : RÃ©cupÃ©ration des 4,872 IDs via `action=query&list=categorymembers`
4. **Extraction par batches** : TÃ©lÃ©chargement du contenu par paquets de 50 pages
5. **Parsing** : Extraction des mÃ©tadonnÃ©es (identifiant, intitulÃ©, rubrique, etc.)
6. **Insertion Supabase** : Sauvegarde avec gestion des doublons
7. **Rapport de complÃ©tude** : Analyse des items manquants/incomplets

### Endpoints utilisÃ©s

```http
# Listing des pages de catÃ©gorie
GET /lisa/2025/api.php?action=query&list=categorymembers&cmtitle=CatÃ©gorie:Objectif_de_connaissance&cmlimit=500&format=json

# Contenu des pages (50 max par requÃªte)
GET /lisa/2025/api.php?action=query&prop=revisions&rvprop=content|timestamp&pageids=123|456|789&format=json&formatversion=2
```

### Parsing des donnÃ©es

**Format identifiant :** `OIC-XXX-YY-R-ZZ`
- `XXX` : Item parent (001-367)
- `YY` : Code rubrique (01-11)
- `R` : Rang (A ou B) 
- `ZZ` : Ordre (01-99)

**Champs extraits :**
- IntitulÃ© : Pattern `|intitulÃ©=...` ou titre de page
- Description : Pattern `|description=...` ou premier paragraphe
- Rubrique : Mapping du code YY vers nom complet
- URL source : ReconstituÃ©e depuis le titre

## ðŸ“Š SchÃ©ma de donnÃ©es

### Table `oic_competences`

```sql
CREATE TABLE oic_competences (
  objectif_id TEXT PRIMARY KEY,           -- OIC-099-01-A-01
  intitule TEXT NOT NULL,                 -- Titre de la compÃ©tence
  item_parent TEXT NOT NULL,              -- 099 (item EDN)
  rang TEXT CHECK (rang IN ('A', 'B')),  -- Niveau de compÃ©tence
  rubrique TEXT,                          -- GÃ©nÃ©tique, CancÃ©rologie, etc.
  description TEXT,                       -- Description dÃ©taillÃ©e
  ordre INTEGER,                          -- 01 (ordre dans le rang)
  url_source TEXT UNIQUE,                 -- URL de la page source
  raw_json JSONB,                         -- Contenu brut pour debug
  date_import TIMESTAMP DEFAULT NOW(),    -- Date d'extraction
  hash_content TEXT,                      -- Hash pour dÃ©tecter doublons
  extraction_status TEXT DEFAULT 'complete'
);
```

### Index de performance

```sql
CREATE INDEX idx_oic_item_parent ON oic_competences(item_parent);
CREATE INDEX idx_oic_rang ON oic_competences(rang);
CREATE INDEX idx_oic_rubrique ON oic_competences(rubrique);
CREATE INDEX idx_oic_date_import ON oic_competences(date_import);
```

## ðŸ“ˆ Rapport de complÃ©tude

Le script gÃ©nÃ¨re automatiquement un rapport JSON dÃ©taillÃ© :

```json
{
  "summary": {
    "total_expected": 4872,
    "total_extracted": 4845,
    "completeness_pct": "99.45",
    "items_covered": 365,
    "items_missing": 2
  },
  "by_item": [
    {
      "item_parent": "001",
      "rang_a_count": 12,
      "rang_b_count": 8,
      "total_count": 20
    }
  ],
  "missing_items": ["042", "156"],
  "generated_at": "2025-01-07T10:30:00.000Z"
}
```

## ðŸ” Debugging

### Logs dÃ©taillÃ©s

Le script affiche des logs complets :

```
ðŸš€ EXTRACTION API-FIRST DES 4,872 OBJECTIFS EDN
===============================================
ðŸ” Test d'accÃ¨s public Ã  l'API MediaWiki...
âœ… API MediaWiki publique accessible!
ðŸ“‹ RÃ©cupÃ©ration des IDs de pages de la catÃ©gorie...
   â†’ 4872 pages OIC trouvÃ©es...
âœ… 4872 pages OIC listÃ©es au total
ðŸ”„ Traitement par batches de 50 pages...
ðŸ“¦ Batch 1/98 - Pages 1 Ã  50
   âœ… 47/50 compÃ©tences insÃ©rÃ©es (3 erreurs)
```

### En cas d'erreur

1. **API inaccessible** : VÃ©rifier la connexion rÃ©seau et les credentials CAS
2. **Parsing Ã©chouÃ©** : Examiner le champ `raw_json` en base pour le format rÃ©el
3. **Insertion Supabase** : VÃ©rifier les contraintes de la table et les permissions RLS

### Reprise d'extraction

Pour reprendre une extraction interrompue :

```bash
# Supprimer les donnÃ©es partielles
DELETE FROM oic_competences WHERE date_import > '2025-01-07 10:00:00';

# Relancer l'extraction
deno run --allow-net --allow-env --allow-write src/scripts/scrape_oic.ts
```

## âš¡ Performance

### MÃ©triques attendues

- **DurÃ©e totale** : 3-5 minutes pour 4,872 pages
- **MÃ©moire** : < 100MB (pas de navigateur headless sauf auth CAS)
- **RequÃªtes rÃ©seau** : ~100 requÃªtes API (vs 4,872 avec Puppeteer)
- **Taux de rÃ©ussite** : > 99% avec gestion d'erreurs robuste

### Optimisations

- Traitement par batches de 50 pages (limite MediaWiki)
- Pause de 1s entre batches pour Ã©viter le rate limiting
- Upsert Supabase avec gestion des doublons
- Authentification CAS minimaliste (Puppeteer uniquement si nÃ©cessaire)

## ðŸ›  Maintenance

### Mise Ã  jour du parsing

Si le format des pages MediaWiki Ã©volue, ajuster les regex dans `parseOICPage()` :

```typescript
const intitulePatterns = [
  /\|\s*[Ii]ntitulÃ©\s*=\s*([^\n\|]+)/,
  /\|\s*[Tt]itre\s*=\s*([^\n\|]+)/,
  // Ajouter nouveaux patterns ici
];
```

### Ajout de nouvelles rubriques

ComplÃ©ter le mapping `RUBRIQUES_MAP` :

```typescript
const RUBRIQUES_MAP: Record<string, string> = {
  '12': 'Nouvelle rubrique',
  // etc.
};
```

### Monitoring

Surveiller les mÃ©triques d'extraction :

- Taux de complÃ©tude par item EDN
- Ã‰volution du nombre total de pages
- FrÃ©quence des Ã©checs de parsing

## ðŸ“ž Support

Pour toute question ou problÃ¨me :

- Slack : @laeticia
- GitHub : Issues sur le repo du projet
- WhatsApp : Contact direct